from controller import Robot, DistanceSensor, Motor, Camera, PositionSensor, GPS, InertialUnit # Added GPS, InertialUnit imports
import socket
import time
import math
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle, FancyArrowPatch, Patch
import json
import numpy as np # Added for image processing

# --- Network Configuration ---
ESP32_IP_ADDRESS = ""
ESP32_PORT = 8080

# --- Robot Physical Parameters ---
WHEEL_RADIUS = 0.0205
AXLE_LENGTH = 0.05720

# --- Grid Configuration ---
GRID_ROWS = 15
GRID_COLS = 21
GRID_CELL_SIZE = 0.05099
GRID_ORIGIN_X = 0.050002
GRID_ORIGIN_Z = -0.639e-05

# --- Navigation Parameters ---
GOAL_ROW = 14
GOAL_COL = 0
FORWARD_SPEED = 1.5
LINE_THRESHOLD = 600

# --- Obstacle Detection Configuration ---
DISTANCE_SENSOR_THRESHOLD = 110
OBSTACLE_DETECTION_ENABLED = True

# --- Camera Configuration & Obstacle Detection ---
CAMERA_NAME = 'camera' # Default camera device name in Webots
# These will be read from the actual camera object, but provide defaults for the class init.
DEFAULT_CAMERA_WIDTH = 40 
DEFAULT_CAMERA_HEIGHT = 1 
# Threshold for camera-based obstacle detection:
# Tune these values based on your simulation environment.
CAMERA_BRIGHTNESS_THRESHOLD = 50 # If average pixel value in ROI is less than this (dark obstacle)
CAMERA_VARIANCE_THRESHOLD = 1000 # If pixel value variance in ROI is greater than this (textured obstacle)


# --- Movement Control Parameters ---
TURN_SPEED_FACTOR = 1.5
MIN_INITIAL_SPIN_DURATION = 0.6
MAX_SEARCH_SPIN_DURATION = 18.9
MAX_ADJUST_DURATION = 2.20
TURN_ADJUST_BASE_SPEED = FORWARD_SPEED * 0.8
TURN_UNTIL_LINE_FOUND = True

# --- Line Following Parameters ---
AGGRESSIVE_CORRECTION_DIFFERENTIAL = FORWARD_SPEED * 1.3
MODERATE_CORRECTION_DIFFERENTIAL = FORWARD_SPEED * 1.2

# --- Starting Position Configuration ---
INITIAL_GRID_ROW = 2
INITIAL_GRID_COL = 20

# --- Visualization Update Rate
VIZ_UPDATE_INTERVAL_SEC = 0.1 # Update visualization every 0.1 seconds (10 Hz) to reduce load

# World grid definition (0 = Black Line, 1 = White Space) - Visual only, for background in matplotlib
world_grid = [
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,0],
    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,1,0,1,0,1,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,1,1,1,1,1,1,1,1,1,0,1,1,1,1,1,1,1,1,1,0],
    [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0],
    [0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1],
    [0,1,0,1,0,1,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1]
]


class CoordinateConverter:
    """Handle conversion between world and grid coordinates."""
    
    @staticmethod
    def world_to_grid(world_x, world_z):
        """Convert world coordinates to grid coordinates."""
        col = round((world_x - GRID_ORIGIN_X) / GRID_CELL_SIZE)
        row = round((world_z - GRID_ORIGIN_Z) / GRID_CELL_SIZE)
        col = max(0, min(col, GRID_COLS - 1))
        row = max(0, min(row, GRID_ROWS - 1))
        return row, col
    
    @staticmethod
    def grid_to_world_center(row, col):
        """Convert grid coordinates to world coordinates (center of cell)."""
        world_x = GRID_ORIGIN_X + col * GRID_CELL_SIZE
        world_z = GRID_ORIGIN_Z + row * GRID_CELL_SIZE
        return world_x, world_z


class CameraObstacleDetector:
    """
    Analyzes raw camera images to detect general obstacles in defined regions
    (front-left, front-center, front-right) and map them to grid cells.
    """
    def __init__(self, camera_width, camera_height, brightness_threshold, variance_threshold):
        self.camera_width = camera_width
        self.camera_height = camera_height
        self.brightness_threshold = brightness_threshold
        self.variance_threshold = variance_threshold
        
        # Define Regions of Interest (ROIs) for obstacle detection
        # These are pixel coordinates relative to the camera image (0,0 is top-left)
        # Assuming the camera is looking slightly downwards, so obstacles appear at the bottom of the image.
        
        # Example ROIs: bottom 20% of image, split into 3 horizontal sections.
        # Adjusted height to start from 80% down to 100% (bottom of image)
        row_start = int(self.camera_height * 0.8) 
        row_end = self.camera_height              
        
        col_width = self.camera_width // 3 # Divide width into 3 regions
        
        self.roi_regions = {
            'front_left': (row_start, row_end, 0, col_width),
            'front_center': (row_start, row_end, col_width, 2 * col_width),
            'front_right': (row_start, row_end, 2 * col_width, self.camera_width)
        }
        print(f"CameraObstacleDetector: Initialized with resolution {self.camera_width}x{self.camera_height}. ROIs defined: {self.roi_regions}")

    def process_image(self, camera_image_data, robot_grid_position, robot_orientation_rad):
        """
        Processes a raw camera image to detect obstacles in predefined regions.
        Converts detected regions into corresponding grid cell obstacles.

        Args:
            camera_image_data (bytes): Raw camera image data (RGB, 3 bytes per pixel).
            robot_grid_position (tuple): Current robot (row, col) grid position.
            robot_orientation_rad (float): Current robot orientation (radians).

        Returns:
            tuple: (list[list], np.array) - List of detected obstacle (row, col) grid positions,
                   and the processed grayscale image data (NumPy array) for visualization.
        """
        detected_grid_obstacles = []
        gray_image = None # Initialize to None in case of error

        if camera_image_data is None:
            return detected_grid_obstacles, gray_image

        try:
            bytes_per_pixel = len(camera_image_data) / (self.camera_width * self.camera_height)
        except ZeroDivisionError:
            print("Camera Error: Camera width or height is zero, cannot process image data.")
            return detected_grid_obstacles, gray_image

        if bytes_per_pixel == 3.0: # RGB image
            try:
                image_np = np.frombuffer(camera_image_data, np.uint8).reshape(
                    (self.camera_height, self.camera_width, 3))
                gray_image = np.mean(image_np, axis=2) # Convert to grayscale for brightness check
            except ValueError as e:
                print(f"Camera Error: Could not reshape RGB camera image data. {e}. Data length: {len(camera_image_data)}")
                return detected_grid_obstacles, gray_image
        elif bytes_per_pixel == 1.0: # Grayscale image
            try:
                image_np = np.frombuffer(camera_image_data, np.uint8).reshape(
                    (self.camera_height, self.camera_width))
                gray_image = image_np # Already grayscale
            except ValueError as e:
                print(f"Camera Error: Could not reshape Grayscale camera image data. {e}. Data length: {len(camera_image_data)}")
                return detected_grid_obstacles, gray_image
        elif bytes_per_pixel == 4.0: # RGBA image (newly added for 4.0 bytes/pixel)
            try:
                image_np = np.frombuffer(camera_image_data, np.uint8).reshape(
                    (self.camera_height, self.camera_width, 4))
                # Convert to grayscale by averaging RGB channels, ignoring the Alpha channel (index 3)
                gray_image = np.mean(image_np[:, :, :3], axis=2) 
            except ValueError as e:
                print(f"Camera Error: Could not reshape RGBA camera image data. {e}. Data length: {len(camera_image_data)}")
                return detected_grid_obstacles, gray_image
        else:
            print(f"Camera Error: Unexpected bytes per pixel: {bytes_per_pixel}. Expected 1, 3, or 4. Data length: {len(camera_image_data)}")
            return detected_grid_obstacles, gray_image

        # Proceed only if gray_image was successfully created
        if gray_image is None:
            return detected_grid_obstacles, gray_image


        for region_name, (r_start, r_end, c_start, c_end) in self.roi_regions.items():
            roi = gray_image[r_start:r_end, c_start:c_end]
            
            if roi.size == 0: # Avoid division by zero if ROI is empty
                continue

            mean_brightness = np.mean(roi)

            # Detection logic: If region is significantly darker than expected background
            if mean_brightness < self.brightness_threshold: # Example: looking for dark obstacles
                obstacle_grid_pos = self._map_camera_region_to_grid(
                    robot_grid_position, robot_orientation_rad, region_name)
                if obstacle_grid_pos:
                    detected_grid_obstacles.append(list(obstacle_grid_pos))
        
        return detected_grid_obstacles, gray_image # Return both detected obstacles and the processed image

    def _map_camera_region_to_grid(self, robot_row_col, robot_orientation_rad, region_name):
        """
        Maps a camera detection region (e.g., 'front_center') to a specific grid cell
        relative to the robot's current pose.
        This mapping depends on camera mounting and robot size.
        """
        r_row, r_col = robot_row_col
        
        # Normalize orientation to 0-360 degrees
        theta_degrees = math.degrees(robot_orientation_rad) % 360
        if theta_degrees < 0: theta_degrees += 360

        delta_row, delta_col = 0, 0 # Default to no change

        # These offsets need careful tuning for your specific camera placement and robot size.
        # They represent how many grid cells "ahead" or "to the side" an obstacle in that camera region is.

        # Facing Right (Yaw ~ 0 deg) (positive X in Webots world)
        if -45 < theta_degrees <= 45: 
            if region_name == 'front_center': delta_row, delta_col = 0, 1 # One cell right
            elif region_name == 'front_right': delta_row, delta_col = -1, 1 # One cell right, one cell up (relative to map)
            elif region_name == 'front_left': delta_row, delta_col = 1, 1 # One cell right, one cell down (relative to map)
        # Facing Down (Yaw ~ 90 deg) (positive Z in Webots world)
        elif 45 < theta_degrees <= 135:
            if region_name == 'front_center': delta_row, delta_col = 1, 0 # One cell down
            elif region_name == 'front_right': delta_row, delta_col = 1, -1 # One cell down, one cell left
            elif region_name == 'front_left': delta_row, delta_col = 1, 1 # One cell down, one cell right
        # Facing Left (Yaw ~ 180 deg) (negative X in Webots world)
        elif 135 < theta_degrees <= 225:
            if region_name == 'front_center': delta_row, delta_col = 0, -1 # One cell left
            elif region_name == 'front_right': delta_row, delta_col = 1, -1 # One cell left, one cell down
            elif region_name == 'front_left': delta_row, delta_col = -1, -1 # One cell left, one cell up
        # Facing Up (Yaw ~ 270 deg) (negative Z in Webots world)
        elif 225 < theta_degrees <= 315:
            if region_name == 'front_center': delta_row, delta_col = -1, 0 # One cell up
            elif region_name == 'front_right': delta_row, delta_col = -1, 1 # One cell up, one cell right
            elif region_name == 'front_left': delta_row, delta_col = -1, -1 # One cell up, one cell left
        
        obstacle_row, obstacle_col = r_row + delta_row, r_col + delta_col
        if 0 <= obstacle_row < GRID_ROWS and 0 <= obstacle_col < GRID_COLS:
            return (obstacle_row, obstacle_col)
        return None


class ObstacleDetector:
    """
    Handle obstacle detection using distance sensors AND camera.
    """
    
    def __init__(self, camera_obstacle_detector_instance): # Now takes camera detector
        self.detected_obstacles = set()
        self.recent_obstacles = [] # For transmission to ESP32
        self.camera_obstacle_detector = camera_obstacle_detector_instance # Store instance
    
    def process_sensor_readings(self, robot_world_pose, robot_orientation, distance_values, camera_data):
        """Process distance sensor readings and camera data to detect obstacles."""
        new_obstacles_this_step = []
        processed_camera_image = None

        current_row, current_col = CoordinateConverter.world_to_grid(
            robot_world_pose['x'], robot_world_pose['z'])
        
        # --- Process Distance Sensor Detections ---
        if OBSTACLE_DETECTION_ENABLED:
            # Process three sensors: front, front-left, front-right (from your original code)
            # Assuming distance_values are ordered as [ps0, ps1, ps2, ..., ps7]
            # And that obstacle_sensors in main are mapped to:
            # obstacle_sensors = [distance_sensors[0], distance_sensors[7], distance_sensors[5]]
            # This means: ps0 (front-right), ps7 (front-left), ps5 (back-right, often used as 'front' in some e-puck setups, or ps2 for front-center)
            # Re-confirming your current obstacle_sensors list: [distance_sensors[0], distance_sensors[7], distance_sensors[5]]
            # If ps5 is meant to be front-center, then sensor_index=2 is correct.
            
            # Remapping for clarity based on your provided obstacle_sensors list:
            # sensor_index 0 -> ps0 (front-right)
            # sensor_index 1 -> ps7 (front-left)
            # sensor_index 2 -> ps5 (could be front-center or other, depending on setup)
            # Let's use generic names to align with _calculate_obstacle_position.
            sensor_logical_names = ['front_right', 'front_left', 'front_center'] # Adjust this if your ps5 is not front-center

            for i, distance_value in enumerate(distance_values):
                if distance_value > DISTANCE_SENSOR_THRESHOLD:
                    obstacle_position = self._calculate_obstacle_position(
                        current_row, current_col, robot_orientation, sensor_logical_names[i])
                    
                    if self._is_valid_position(obstacle_position):
                        if obstacle_position not in self.detected_obstacles:
                            new_obstacles_this_step.append(obstacle_position)
                            self.detected_obstacles.add(obstacle_position)
                            self.recent_obstacles.append(obstacle_position) # Add to recent for ESP32

        # --- Process Camera Detections ---
        if self.camera_obstacle_detector and camera_data:
            camera_detected_grid_obstacles, processed_camera_image = self.camera_obstacle_detector.process_image(
                camera_data, (current_row, current_col), robot_orientation)
            
            for obs_pos_list in camera_detected_grid_obstacles:
                obs_pos_tuple = tuple(obs_pos_list) # Convert to tuple for set operations
                if obs_pos_tuple not in self.detected_obstacles:
                    new_obstacles_this_step.append(obs_pos_tuple)
                    self.detected_obstacles.add(obs_pos_tuple)
                    self.recent_obstacles.append(obs_pos_tuple) # Add to recent for ESP32

        return new_obstacles_this_step, processed_camera_image # Return both new obstacles and image

    def _calculate_obstacle_position(self, robot_row, robot_col, orientation, sensor_logical_name):
        """Calculate obstacle position based on robot orientation and sensor."""
        theta_degrees = math.degrees(orientation) % 360
        if theta_degrees < 0: theta_degrees += 360
        
        delta_row, delta_col = 0, 0 # Default to no change

        # These offsets predict the cell an obstacle would be in based on robot facing direction.
        # This mapping is crucial and should accurately reflect your robot's sensor placement.
        
        # Robot facing RIGHT (Yaw ~ 0 deg) (matches odometry theta=0)
        if -45 < theta_degrees <= 45: 
            if sensor_logical_name == 'front_center': delta_row, delta_col = 0, 1 
            elif sensor_logical_name == 'front_right': delta_row, delta_col = -1, 1 
            elif sensor_logical_name == 'front_left': delta_row, delta_col = 1, 1 
        # Robot facing DOWN (Yaw ~ 90 deg) (matches odometry theta=pi/2)
        elif 45 < theta_degrees <= 135:
            if sensor_logical_name == 'front_center': delta_row, delta_col = 1, 0
            elif sensor_logical_name == 'front_right': delta_row, delta_col = 1, -1 
            elif sensor_logical_name == 'front_left': delta_row, delta_col = 1, 1 
        # Robot facing LEFT (Yaw ~ 180 deg) (matches odometry theta=pi)
        elif 135 < theta_degrees <= 225:
            if sensor_logical_name == 'front_center': delta_row, delta_col = 0, -1
            elif sensor_logical_name == 'front_right': delta_row, delta_col = 1, -1 
            elif sensor_logical_name == 'front_left': delta_row, delta_col = -1, -1 
        # Robot facing UP (Yaw ~ 270 deg) (matches odometry theta=-pi/2 or 3pi/2)
        elif 225 < theta_degrees <= 315:
            if sensor_logical_name == 'front_center': delta_row, delta_col = -1, 0
            elif sensor_logical_name == 'front_right': delta_row, delta_col = -1, 1 
            elif sensor_logical_name == 'front_left': delta_row, delta_col = -1, -1 
        
        return (robot_row + delta_row, robot_col + delta_col)
    
    def _is_valid_position(self, position):
        """Check if position is within grid bounds."""
        row, col = position
        return 0 <= row < GRID_ROWS and 0 <= col < GRID_COLS
    
    def get_recent_obstacles(self):
        """Get and clear recent obstacles for transmission."""
        obstacles = self.recent_obstacles.copy()
        self.recent_obstacles.clear()
        return obstacles
    
    # Removed add_recent_obstacles as it's now internal to process_sensor_readings


class VisualizationManager:
    """
    Manage real-time visualization of navigation system, including a camera feed.
    Now also displays odometry vs. ground truth pose errors.
    """
    
    def __init__(self):
        self.figure = None
        self.axis = None # For the main map plot
        self.camera_ax = None # New axis for camera feed
        self.camera_image_artist = None # Artist object for updating camera image efficiently

        self.robot_trail = []
        self.planned_path = []
        self.obstacle_cells_for_viz = set() # Copy of detected obstacles for visualization
        
        # Specific Line2D/Patch objects that will be updated or removed
        self.robot_position_marker = None
        self.robot_orientation_arrow = None
        self.current_waypoint_marker = None
        self.goal_marker = None 
        self.info_text = None # System info text, now includes errors
        
        self.robot_trail_line = None
        self.planned_path_line = None
    
    def initialize_display(self, camera_width, camera_height):
        """Initialize matplotlib visualization with multiple subplots."""
        plt.ion() # Turn on interactive mode
        
        # Create a figure with two subplots: one for the map, one for the camera
        self.figure, (self.axis, self.camera_ax) = plt.subplots(1, 2, figsize=(18, 9), gridspec_kw={'width_ratios': [2, 1]}) # Map is wider
        
        # --- Configure Map Subplot ---
        self.axis.set_aspect('equal') # Ensure square grid cells
        self.axis.set_title('Hardware-in-the-Loop Navigation System (Map)', fontsize=16, fontweight='bold')
        self.axis.set_xlabel('World X (m)', fontsize=12)
        self.axis.set_ylabel('World Z (m)', fontsize=12)
        
        self._draw_grid_lines()
        self._setup_display_limits()
        self._create_legend() # Legend on the map subplot

        # --- Configure Camera Subplot ---
        self.camera_ax.set_title('Robot Camera Feed (Grayscale)', fontsize=14, fontweight='bold')
        self.camera_ax.set_xticks([]) # Hide x ticks
        self.camera_ax.set_yticks([]) # Hide y ticks
        self.camera_ax.set_aspect('auto') # Let camera aspect ratio be determined by image size
        
        # Initialize the camera image artist with dummy data
        dummy_image = np.zeros((camera_height, camera_width), dtype=np.uint8)
        self.camera_image_artist = self.camera_ax.imshow(dummy_image, cmap='gray', vmin=0, vmax=255)
        
        plt.tight_layout(rect=[0, 0, 0.95, 1]) # Adjust layout to give some space to the right
        plt.show(block=False)
        plt.pause(0.01) # Small pause to allow plot to render
    
    def _draw_grid_lines(self):
        """Draw grid overlay on visualization."""
        # Horizontal lines
        for row in range(GRID_ROWS + 1):
            z_coord = GRID_ORIGIN_Z + row * GRID_CELL_SIZE
            self.axis.plot([GRID_ORIGIN_X, GRID_ORIGIN_X + GRID_COLS * GRID_CELL_SIZE], 
                           [z_coord, z_coord], 'k-', alpha=0.2, lw=0.5, zorder=1) # Lower zorder
        
        # Vertical lines
        for col in range(GRID_COLS + 1):
            x_coord = GRID_ORIGIN_X + col * GRID_CELL_SIZE
            self.axis.plot([x_coord, x_coord], 
                           [GRID_ORIGIN_Z, GRID_ORIGIN_Z + GRID_ROWS * GRID_CELL_SIZE], 
                           'k-', alpha=0.2, lw=0.5, zorder=1) # Lower zorder
    
    def _setup_display_limits(self):
        """Set appropriate display limits with margin."""
        margin = GRID_CELL_SIZE * 2
        self.axis.set_xlim(GRID_ORIGIN_X - margin, GRID_ORIGIN_X + GRID_COLS * GRID_CELL_SIZE + margin)
        self.axis.set_ylim(GRID_ORIGIN_Z - margin, GRID_ORIGIN_Z + GRID_ROWS * GRID_CELL_SIZE + margin)
    
    def _create_legend(self):
        """Create legend for visualization elements."""
        legend_elements = [
            Patch(facecolor='black', alpha=0.7, label='Black Line Path'),
            Patch(facecolor='lightgrey', alpha=0.3, label='White Space'),
            Patch(facecolor='red', alpha=0.7, label='Detected Obstacle'),
            plt.Line2D([0], [0], color='cyan', lw=2, label='Robot Trail'),
            plt.Line2D([0], [0], color='magenta', marker='o', ms=5, ls='--', lw=2, label='Planned Path'),
            plt.Line2D([0], [0], color='red', marker='o', ms=8, ls='', label='Robot Position'),
            plt.Line2D([0], [0], color='green', marker='*', ms=12, ls='', label='Goal Position')
        ]
        self.axis.legend(handles=legend_elements, loc='upper left', bbox_to_anchor=(1.02, 1))
    
    def update_display(self, robot_world_pose, robot_grid_position, line_sensors, planned_path, 
                       all_detected_obstacles, processed_camera_image=None, 
                       position_error=0.0, orientation_error=0.0): # Added error arguments
        """Update visualization with current system state."""
        if self.figure is None:
            # Initialize with actual camera dimensions if available, otherwise defaults
            # This is handled in main() before calling update_display for the first time.
            # So, the initialize_display will be called once with correct camera_width/height.
            self.initialize_display(DEFAULT_CAMERA_WIDTH, DEFAULT_CAMERA_HEIGHT) # Placeholder, will be corrected in main
        
        self._clear_dynamic_elements()
        self.obstacle_cells_for_viz = all_detected_obstacles # Update the set for drawing
        self._draw_grid_cells()
        self._update_robot_trail(robot_world_pose)
        self._draw_planned_path(planned_path)
        self._draw_robot_state(robot_world_pose, robot_grid_position, line_sensors)
        self._draw_goal_position()
        self._display_system_info(robot_grid_position, line_sensors, len(self.obstacle_cells_for_viz),
                                  position_error, orientation_error) # Pass errors to info display
        
        # --- Update Camera Display ---
        if processed_camera_image is not None and self.camera_image_artist is not None:
            # Set the new data for the image artist
            self.camera_image_artist.set_data(processed_camera_image)
            # Update the extent if the dimensions might change (though they shouldn't for Webots camera)
            self.camera_image_artist.set_extent([0, processed_camera_image.shape[1], processed_camera_image.shape[0], 0])
            # Ensure proper scaling for the camera axes
            self.camera_ax.set_xlim(0, processed_camera_image.shape[1])
            self.camera_ax.set_ylim(processed_camera_image.shape[0], 0) # Invert y-axis for standard image display
            
        plt.draw()
        plt.pause(0.001)
    
    def _clear_dynamic_elements(self):
        """Clear dynamic visualization elements for redraw."""
        # Clear patches (rectangles for grid cells, arrows)
        for patch in self.axis.patches[:]: # Iterate over a copy of the list
            patch.remove()
        
        # Clear specific Line2D objects managed by instance variables
        if self.robot_trail_line:
            self.robot_trail_line.remove()
            self.robot_trail_line = None
        
        if self.planned_path_line:
            self.planned_path_line.remove()
            self.planned_path_line = None

        if self.robot_position_marker:
            self.robot_position_marker.remove()
            self.robot_position_marker = None
        
        if self.current_waypoint_marker: # This was not managed explicitly before, adding for clarity
            self.current_waypoint_marker.remove()
            self.current_waypoint_marker = None

        # self.robot_orientation_arrow is a FancyArrowPatch, which is a subclass of Patch,
        # so it's handled by clearing self.axis.patches. Explicitly setting to None here
        # ensures its reference is correctly reset.
        self.robot_orientation_arrow = None

        # Clear existing text elements (system info)
        if self.info_text:
            self.info_text.remove()
            self.info_text = None

    def _draw_grid_cells(self):
        """Draw grid cells with appropriate coloring."""
        for row in range(GRID_ROWS):
            for col in range(GRID_COLS):
                center_x, center_z = CoordinateConverter.grid_to_world_center(row, col)
                
                # Determine cell color based on obstacle status
                if (row, col) in self.obstacle_cells_for_viz: # Use the viz-specific set
                    color, alpha = 'red', 0.7
                else:
                    color = 'black' if world_grid[row][col] == 0 else 'lightgrey'
                    alpha = 0.6 if color == 'black' else 0.3
                
                rect = plt.Rectangle(
                    (center_x - GRID_CELL_SIZE/2, center_z - GRID_CELL_SIZE/2),
                    GRID_CELL_SIZE, GRID_CELL_SIZE,
                    facecolor=color, alpha=alpha, edgecolor='gray', linewidth=0.5,
                    zorder=2 # Ensure grid cells are below markers/paths
                )
                self.axis.add_patch(rect)
    
    def _update_robot_trail(self, robot_world_pose):
        """Update and display robot movement trail."""
        self.robot_trail.append((robot_world_pose['x'], robot_world_pose['z']))
        if len(self.robot_trail) > 200:
            self.robot_trail.pop(0)
        
        if len(self.robot_trail) > 1:
            # Create a new line object each time, the old one is removed by _clear_dynamic_elements
            self.robot_trail_line, = self.axis.plot(
                [p[0] for p in self.robot_trail], 
                [p[1] for p in self.robot_trail], 
                color='cyan', lw=2, alpha=0.7, zorder=5
            )
    
    def _draw_planned_path(self, planned_path):
        """Display planned path if available."""
        self.planned_path = planned_path # Update the stored path
        if planned_path and len(planned_path) > 1:
            path_world = [CoordinateConverter.grid_to_world_center(r, c) for r, c in planned_path]
            if path_world:
                path_x, path_z = zip(*path_world)
                # Create a new line object each time
                self.planned_path_line, = self.axis.plot(
                    path_x, path_z, 'mo--', lw=2, ms=5, alpha=0.8, zorder=4,
                    label='Planned Path' # Ensure label for legend
                )
    
    def _draw_robot_state(self, robot_world_pose, robot_grid_position, line_sensors):
        """Draw robot position and orientation."""
        # Robot position marker
        self.robot_position_marker, = self.axis.plot(
            robot_world_pose['x'], robot_world_pose['z'], 'ro', ms=10, 
            mec='darkred', mew=1, zorder=7 # Ensure marker is on top
        )
        
        # Orientation arrow
        arrow_length = GRID_CELL_SIZE * 0.7
        dx = arrow_length * math.cos(robot_world_pose['theta'])
        dz = arrow_length * math.sin(robot_world_pose['theta'])
        arrow = FancyArrowPatch(
            (robot_world_pose['x'], robot_world_pose['z']), 
            (robot_world_pose['x'] + dx, robot_world_pose['z'] + dz),
            arrowstyle='->', mutation_scale=15, color='darkred', lw=2,
            zorder=8 # Ensure arrow is on top of marker
        )
        self.axis.add_patch(arrow)
        
        # Highlight current grid cell
        if robot_grid_position:
            self._highlight_current_cell(robot_grid_position, line_sensors)
    
    def _highlight_current_cell(self, grid_position, line_sensors):
        """Highlight robot's current grid cell."""
        center_x, center_z = CoordinateConverter.grid_to_world_center(grid_position[0], grid_position[1])
        sensors_active = any(line_sensors)
        
        highlight_color = 'green' if sensors_active else 'yellow'
        highlight_alpha = 0.5 if sensors_active else 0.3
        
        highlight_rect = plt.Rectangle(
            (center_x - GRID_CELL_SIZE/2, center_z - GRID_CELL_SIZE/2),
            GRID_CELL_SIZE, GRID_CELL_SIZE,
            edgecolor=highlight_color, facecolor=highlight_color, 
            alpha=highlight_alpha, linewidth=3, zorder=6 # Ensure highlight is above grid cells
        )
        self.axis.add_patch(highlight_rect)
        
        # Status text
        sensor_status = "ON LINE" if sensors_active else "NO LINE"
        status_color = 'green' if sensors_active else 'orange'
        
        self.axis.text(center_x, center_z + GRID_CELL_SIZE * 0.6, sensor_status, 
                       ha='center', va='bottom', fontsize=7, color=status_color, weight='bold',
                       bbox=dict(boxstyle='round,pad=0.2', facecolor='white', alpha=0.8), zorder=9) # On top
    
    def _draw_goal_position(self):
        """Draw goal position marker."""
        goal_x, goal_z = CoordinateConverter.grid_to_world_center(GOAL_ROW, GOAL_COL)
        # Ensure goal marker is only drawn once (it's static)
        if self.goal_marker is None or not self.goal_marker.get_visible():
            self.goal_marker, = self.axis.plot(
                goal_x, goal_z, 'g*', ms=15, mec='darkgreen', mew=1.5, zorder=9,
                label='Goal Position' # Ensure label for legend
            )

    def _display_system_info(self, grid_position, line_sensors, num_obstacles_detected,
                             position_error, orientation_error): # Added error arguments
        """Display system information panel."""
        line_status = "ON BLACK LINE" if any(line_sensors) else "NO LINE DETECTED"
        info_background = 'lightgreen' if any(line_sensors) else 'lightcoral'
        
        info_text = (f"Grid Position: {grid_position} -> Goal: ({GOAL_ROW},{GOAL_COL})\n"
                     f"Sensor Status: {line_status}\n"
                     f"Obstacles Detected: {num_obstacles_detected}\n"
                     f"Pos Error (m): {position_error:.3f}\n" # Display position error
                     f"Orient Error (deg): {math.degrees(orientation_error):.1f}") # Display orientation error in degrees
        
        # Update or create the text element
        if self.info_text is None:
            self.info_text = self.axis.text(0.02, 0.98, info_text,
                                            transform=self.axis.transAxes, va='top', fontsize=8,
                                            bbox=dict(boxstyle='round,pad=0.4', facecolor=info_background, alpha=0.8))
        else:
            self.info_text.set_text(info_text)


class TurnController:
    """Handle robot turning operations with line detection."""
    
    def __init__(self):
        self.current_phase = 'NONE'
        self.active_command = None
        self.phase_start_time = 0.0
    
    def initiate_turn(self, turn_direction, current_time):
        """Start a new turning operation."""
        if self.active_command != turn_direction or self.current_phase == 'NONE':
            self.active_command = turn_direction
            self.current_phase = 'INITIATE_SPIN'
            self.phase_start_time = current_time
    
    def execute_turn(self, turn_direction, line_sensors, current_time):
        """Execute turn operation and return motor speeds."""
        if self.current_phase == 'INITIATE_SPIN':
            return self._execute_initial_spin(current_time)
        elif self.current_phase == 'SEARCHING_LINE':
            return self._execute_line_search(line_sensors, current_time)
        elif self.current_phase == 'ADJUSTING_ON_LINE':
            return self._execute_line_adjustment(line_sensors, current_time)
        
        return 0.0, 0.0
    
    def _execute_initial_spin(self, current_time):
        """Execute initial spin phase to get off current line."""
        spin_speeds = self._calculate_turn_speeds(0.8, 1.1)
        
        if current_time - self.phase_start_time > MIN_INITIAL_SPIN_DURATION:
            self.current_phase = 'SEARCHING_LINE'
            self.phase_start_time = current_time
        
        return spin_speeds
    
    def _execute_line_search(self, line_sensors, current_time):
        """Search for line during turn operation."""
        search_speeds = self._calculate_turn_speeds(0.5, 0.9)
        
        if any(line_sensors):
            self.current_phase = 'ADJUSTING_ON_LINE'
            self.phase_start_time = current_time
        elif (not TURN_UNTIL_LINE_FOUND and 
              current_time - self.phase_start_time > MAX_SEARCH_SPIN_DURATION):
            self.current_phase = 'NONE'
            return 0.0, 0.0
        
        return search_speeds
    
    def _execute_line_adjustment(self, line_sensors, current_time):
        """Fine-tune position on detected line."""
        left_sensor, center_sensor, right_sensor = line_sensors
        base_speed = TURN_ADJUST_BASE_SPEED
        moderate_diff = MODERATE_CORRECTION_DIFFERENTIAL * (base_speed / FORWARD_SPEED)
        aggressive_diff = AGGRESSIVE_CORRECTION_DIFFERENTIAL * (base_speed / FORWARD_SPEED)
        
        if not left_sensor and center_sensor and not right_sensor:
            # Perfect center - turn complete
            self.current_phase = 'NONE'
            self.active_command = None
            return base_speed * 0.3, base_speed * 0.3
        elif left_sensor and center_sensor and not right_sensor:
            return base_speed - moderate_diff, base_speed
        elif not left_sensor and center_sensor and right_sensor:
            return base_speed, base_speed - moderate_diff
        elif left_sensor and not center_sensor and not right_sensor:
            return base_speed - aggressive_diff, base_speed
        elif not left_sensor and not center_sensor and right_sensor:
            return base_speed, base_speed - aggressive_diff
        elif left_sensor and center_sensor and right_sensor:
            return base_speed * 0.7, base_speed * 0.7
        elif not any(line_sensors):
            # Line lost - return to search
            self.current_phase = 'SEARCHING_LINE'
            self.phase_start_time = current_time
            return self._calculate_turn_speeds(0.5, 0.9)
        else:
            return base_speed * 0.7, base_speed * 0.7
        
        # Timeout check
        if current_time - self.phase_start_time > MAX_ADJUST_DURATION:
            self.current_phase = 'NONE'
            self.active_command = None
            return 0.0, 0.0
    
    def _calculate_turn_speeds(self, inner_factor, outer_factor):
        """Calculate motor speeds for turning."""
        inner_speed = -FORWARD_SPEED * TURN_SPEED_FACTOR * inner_factor
        outer_speed = FORWARD_SPEED * TURN_SPEED_FACTOR * outer_factor
        
        if self.active_command == 'turn_left':
            return inner_speed, outer_speed
        else:  # turn_right
            return outer_speed, inner_speed
    
    def is_turning(self):
        """Check if currently executing a turn."""
        return self.current_phase != 'NONE'
    
    def reset(self):
        """Reset turn controller state."""
        self.current_phase = 'NONE'
        self.active_command = None


class NetworkManager:
    """Handle network communication with ESP32."""
    
    def __init__(self, esp32_ip, esp32_port):
        self.esp32_ip = esp32_ip
        self.esp32_port = esp32_port
        self.client_socket = None
        self.is_connected = False
    
    def establish_connection(self):
        """Establish connection to ESP32."""
        try:
            if self.client_socket:
                self.client_socket.close()
            self.client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
            self.client_socket.settimeout(2.0)
            self.client_socket.connect((self.esp32_ip, self.esp32_port))
            self.client_socket.settimeout(0.05)
            self.is_connected = True
            print("ESP32 Connection Established")
            return True
        except Exception as e: # Catch all exceptions during connection attempt
            print(f"Webots Error (Connect): {e}")
            self.is_connected = False
            self.client_socket = None
            return False
    
    def send_data(self, data):
        """Send data to ESP32."""
        try:
            message = json.dumps(data) + '\n'
            self.client_socket.sendall(message.encode('utf-8'))
            return True
        except Exception as e:
            print(f"Webots Error (Send): {e}")
            self.is_connected = False
            return False
    
    def receive_data(self, buffer_size=1024): # Added buffer_size for clarity
        """Receive data from ESP32."""
        try:
            response = self.client_socket.recv(buffer_size)
            if response:
                messages = response.decode('utf-8').strip().split('\n')
                return [msg for msg in messages if msg.strip()]
            return [] # Empty response implies connection closed by ESP32
        except socket.timeout:
            return [] # No data yet, not an error
        except Exception as e:
            # Catch ConnectionResetError (104) or other issues
            # if the client_socket is invalid, it means connection lost.
            print(f"Webots Error (Receive): {e}")
            self.is_connected = False
            return []
    
    def close_connection(self):
        """Close network connection."""
        if self.client_socket:
            try:
                self.client_socket.close()
            except Exception as e:
                print(f"Error closing socket: {e}")
            finally:
                self.client_socket = None
        self.is_connected = False


def initialize_robot_systems():
    """Initialize all robot hardware systems."""
    robot = Robot()
    timestep = int(robot.getBasicTimeStep())
    
    # --- GPS and InertialUnit for ground truth comparison ---
    # IMPORTANT: These variables MUST be initialized to None to prevent NameError
    gps_device = None
    inertial_unit_device = None

    # Retrieve devices. They will be None if not found in the world.
    gps_device = robot.getDevice('gps')
    if gps_device:
        gps_device.enable(timestep)
        print("Webots: GPS device initialized.")
    else:
        print("Webots Warning: GPS device 'gps' not found. Position ground truth comparison will not work.")

    inertial_unit_device = robot.getDevice('inertial unit')
    if inertial_unit_device:
        inertial_unit_device.enable(timestep)
        print("Webots: InertialUnit device initialized.")
    else:
        print("Webots Warning: InertialUnit device 'inertial unit' not found. Orientation ground truth comparison will not work.")
    # --- End GPS/InertialUnit ---

    # Initialize motors
    left_motor = robot.getDevice('left wheel motor')
    right_motor = robot.getDevice('right wheel motor')
    for motor in [left_motor, right_motor]:
        motor.setPosition(float('inf'))
        motor.setVelocity(0.0)
    
    # Initialize encoders
    left_encoder = robot.getDevice('left wheel sensor')
    right_encoder = robot.getDevice('right wheel sensor')
    for encoder in [left_encoder, right_encoder]:
        if encoder: # Ensure encoder exists before enabling
            encoder.enable(timestep)
        else:
            print(f"Webots Error: Encoder not found. Check 'left wheel sensor' or 'right wheel sensor'.")
            
    # Initialize ground sensors
    ground_sensors = []
    line_sensor_names = ['gs0', 'gs1', 'gs2'] # Consistent list name
    for name in line_sensor_names:
        sensor = robot.getDevice(name)
        if sensor:
            sensor.enable(timestep)
            ground_sensors.append(sensor)
        else:
            print(f"Webots Warning: Line sensor '{name}' not found. Check your robot model.")
    
    # Initialize distance sensors
    distance_sensors_all = [] # Get all distance sensors first
    sensor_names_all = ['ps0', 'ps1', 'ps2', 'ps3', 'ps4', 'ps5', 'ps6', 'ps7']
    for name in sensor_names_all:
        sensor = robot.getDevice(name)
        if sensor:
            sensor.enable(timestep)
            distance_sensors_all.append(sensor)
        else:
            print(f"Webots Warning: Distance sensor '{name}' not found.")
            # Append None or handle it if you need a specific count
            distance_sensors_all.append(None) # To maintain index alignment if needed

    # Select specific sensors for obstacle detection based on their indices in the full list
    # Your original code used indices 0, 7, 5 which correspond to ps0, ps7, ps5
    # Make sure these are the sensors you intend for front-right, front-left, front-center
    obstacle_sensors = [s for i, s in enumerate(distance_sensors_all) if i in [0, 7, 5] and s is not None]
    if len(obstacle_sensors) != 3:
        print("Webots Warning: Not all 3 specified obstacle sensors (ps0, ps7, ps5) were found for obstacle detection.")

    # Initialize Camera Device
    camera = robot.getDevice(CAMERA_NAME)
    actual_camera_width = DEFAULT_CAMERA_WIDTH 
    actual_camera_height = DEFAULT_CAMERA_HEIGHT 

    if camera:
        camera.enable(timestep)
        actual_camera_width = camera.getWidth()
        actual_camera_height = camera.getHeight()
        print(f"Webots: Camera '{CAMERA_NAME}' initialized with resolution {actual_camera_width}x{actual_camera_height}.")
    else:
        print(f"Webots Error: Camera '{CAMERA_NAME}' not found. Camera-based obstacle detection/display will not work.")
    
    return {
        'robot': robot,
        'timestep': timestep,
        'left_motor': left_motor,
        'right_motor': right_motor,
        'left_encoder': left_encoder,
        'right_encoder': right_encoder,
        'ground_sensors': ground_sensors,
        'obstacle_sensors': obstacle_sensors, # Passed as filtered list of actual sensors
        'camera': camera,
        'actual_camera_width': actual_camera_width,
        'actual_camera_height': actual_camera_height,
        'gps_device': gps_device, # Return GPS device
        'inertial_unit_device': inertial_unit_device # Return InertialUnit device
    }


def update_robot_odometry(world_pose, encoders, first_update):
    """Update robot position using wheel encoder odometry."""
    # Ensure encoders are valid before proceeding
    if not encoders['left_encoder'] or not encoders['right_encoder']:
        print("Webots Error: Odometry cannot update, encoders not found.")
        # Return current pose as-is, or indicate failure
        return world_pose, encoders.get('prev_left', 0.0), encoders.get('prev_right', 0.0), first_update

    if first_update:
        prev_left = encoders['left_encoder'].getValue()
        prev_right = encoders['right_encoder'].getValue()
        return world_pose, prev_left, prev_right, False
    
    current_left = encoders['left_encoder'].getValue()
    current_right = encoders['right_encoder'].getValue()
    
    left_diff = current_left - encoders['prev_left']
    right_diff = current_right - encoders['prev_right']
    
    # Calculate movement
    distance = (left_diff * WHEEL_RADIUS + right_diff * WHEEL_RADIUS) / 2.0
    rotation = (right_diff * WHEEL_RADIUS - left_diff * WHEEL_RADIUS) / AXLE_LENGTH
    
    # Update position
    world_pose['x'] += distance * math.cos(world_pose['theta'] + rotation / 2.0)
    world_pose['z'] += distance * math.sin(world_pose['theta'] + rotation / 2.0)
    world_pose['theta'] = math.atan2(
        math.sin(world_pose['theta'] + rotation), 
        math.cos(world_pose['theta'] + rotation)
    )
    
    return world_pose, current_left, current_right, first_update


def calculate_line_following_speeds(line_sensors):
    """Calculate motor speeds for line following behavior."""
    # Ensure line_sensors has 3 elements, if not, fill with 0s
    if len(line_sensors) < 3:
        line_sensors_padded = line_sensors + [0] * (3 - len(line_sensors))
    else:
        line_sensors_padded = line_sensors[:3] # Use only first 3 if more are present

    left_sensor, center_sensor, right_sensor = line_sensors_padded
    base_speed = FORWARD_SPEED
    
    if not left_sensor and center_sensor and not right_sensor:
        return base_speed, base_speed
    elif left_sensor and center_sensor and not right_sensor:
        return base_speed - MODERATE_CORRECTION_DIFFERENTIAL, base_speed
    elif not left_sensor and center_sensor and right_sensor:
        return base_speed, base_speed - MODERATE_CORRECTION_DIFFERENTIAL
    elif left_sensor and not center_sensor and not right_sensor:
        return base_speed - AGGRESSIVE_CORRECTION_DIFFERENTIAL, base_speed
    elif not left_sensor and not center_sensor and right_sensor:
        return base_speed, base_speed - AGGRESSIVE_CORRECTION_DIFFERENTIAL
    elif left_sensor and center_sensor and right_sensor:
        return base_speed * 0.7, base_speed * 0.7
    elif not any(line_sensors_padded): # Check padded version
        return base_speed * 0.2, base_speed * 0.2
    else:
        return base_speed * 0.3, base_speed * 0.3


def main():
    """Main program execution loop."""
    # Initialize systems
    hardware = initialize_robot_systems()
    # Initialize visualization with actual camera dimensions
    visualization = VisualizationManager()
    visualization.initialize_display(hardware['actual_camera_width'], hardware['actual_camera_height'])

    turn_controller = TurnController()
    network_manager = NetworkManager(ESP32_IP_ADDRESS, ESP32_PORT)
    
    # Initialize robot state
    robot_world_pose = {
        'x': CoordinateConverter.grid_to_world_center(INITIAL_GRID_ROW, INITIAL_GRID_COL)[0],
        'z': CoordinateConverter.grid_to_world_center(INITIAL_GRID_ROW, INITIAL_GRID_COL)[1],
        'theta': math.pi / 2.0 # Initial orientation for the odometry tracker
    }
    
    current_grid_position = CoordinateConverter.world_to_grid(robot_world_pose['x'], robot_world_pose['z'])
    planned_path = []
    esp32_command = 'stop'
    
    # Control loop variables
    iteration_count = 0
    last_connection_attempt = 0
    last_data_transmission = 0
    last_viz_update_time = 0.0 # Control visualization update rate
    first_odometry_update = True
    encoder_values = {'prev_left': 0.0, 'prev_right': 0.0}
    
    # Obstacle detector instance, now passes the camera detector
    camera_obs_detector_instance = CameraObstacleDetector(
        hardware['actual_camera_width'], hardware['actual_camera_height'], 
        CAMERA_BRIGHTNESS_THRESHOLD, CAMERA_VARIANCE_THRESHOLD
    )
    obstacle_detector = ObstacleDetector(camera_obs_detector_instance)

    # Variables for pose comparison
    current_position_error = 0.0
    current_orientation_error = 0.0

    print("Hardware-in-the-Loop Navigation System Started")
    
    # Main control loop
    while hardware['robot'].step(hardware['timestep']) != -1:
        current_time = hardware['robot'].getTime()
        iteration_count += 1
        
        # Read sensor data
        line_sensor_values = [s.getValue() for s in hardware['ground_sensors']]
        line_detected = [1 if v < LINE_THRESHOLD else 0 for v in line_sensor_values] # Binary status for line following
        
        # Ensure obstacle_sensors is not empty before attempting to get values
        obstacle_sensor_values = [s.getValue() for s in hardware['obstacle_sensors'] if s is not None]
        
        # Get raw camera image data
        camera_image_data = hardware['camera'].getImage() if hardware['camera'] else None
        
        # Update robot position using odometry
        # Needs to check if encoders are valid first
        if hardware['left_encoder'] and hardware['right_encoder']:
            robot_world_pose, encoder_values['prev_left'], encoder_values['prev_right'], first_odometry_update = \
                update_robot_odometry(robot_world_pose, {
                    'left_encoder': hardware['left_encoder'],
                    'right_encoder': hardware['right_encoder'],
                    'prev_left': encoder_values['prev_left'],
                    'prev_right': encoder_values['prev_right']
                }, first_odometry_update)
        else:
            print("Webots: Encoders not ready for odometry. Robot pose will not be updated by odometry.")
            # Set odometry pose to NaN or a known error state if encoders are missing.
            # This will result in NaN errors if used for calculations, which is desired behavior if odometry is broken.
            if not math.isnan(robot_world_pose['x']): # Only if not already NaN
                robot_world_pose['x'] = float('nan')
                robot_world_pose['z'] = float('nan')
                robot_world_pose['theta'] = float('nan')


        current_grid_position = CoordinateConverter.world_to_grid(robot_world_pose['x'], robot_world_pose['z'])
        
        # --- Get Webots Ground Truth Pose from GPS/InertialUnit and Calculate Errors ---
        gt_x, gt_z, gt_theta = float('nan'), float('nan'), float('nan') # Initialize with NaN (Not a Number)

        # Get ground truth position from GPS
        if hardware['gps_device']: # Check if device exists before trying to read
            gps_values = hardware['gps_device'].getValues() # [x, y, z]
            # Webots GPS gives X, Y (vertical), Z. We need X and Z for our 2D ground plane.
            gt_x = gps_values[0] 
            gt_z = gps_values[2] 
        else:
            # Print warning only once or less frequently to avoid console spam
            if iteration_count % 100 == 0:
                print("Webots: GPS device not available for ground truth position.")

        # Get ground truth orientation from InertialUnit
        if hardware['inertial_unit_device']: # Check if device exists before trying to read
            # InertialUnit provides roll, pitch, yaw. Yaw (heading) is typically the 3rd element (index 2).
            # This is the rotation around the Y-axis.
            rpy_values = hardware['inertial_unit_device'].getRollPitchYaw()
            gt_theta = rpy_values[2] # Yaw is the third component (index 2)
        else:
            if iteration_count % 100 == 0:
                print("Webots: InertialUnit device not available for ground truth orientation.")


        # Calculate position error (Euclidean distance on XZ plane) if ground truth is valid
        if not math.isnan(gt_x) and not math.isnan(gt_z) and \
           not math.isnan(robot_world_pose['x']) and not math.isnan(robot_world_pose['z']):
            current_position_error = math.sqrt(
                (robot_world_pose['x'] - gt_x)**2 +
                (robot_world_pose['z'] - gt_z)**2 
            )
        else:
            current_position_error = float('nan') # Error cannot be calculated if data is missing

        # Calculate orientation error (shortest angle difference) if ground truth is valid
        if not math.isnan(gt_theta) and not math.isnan(robot_world_pose['theta']):
            angle_diff = robot_world_pose['theta'] - gt_theta
            current_orientation_error = math.atan2(math.sin(angle_diff), math.cos(angle_diff))
        else:
            current_orientation_error = float('nan') # Error cannot be calculated if data is missing
        
        # Process obstacle detection (no rate limit here; process every step to be responsive)
        new_obstacles, processed_camera_image = obstacle_detector.process_sensor_readings(
            robot_world_pose, robot_world_pose['theta'], obstacle_sensor_values, camera_image_data)
        
        # Handle network communication
        if not network_manager.is_connected:
            if current_time - last_connection_attempt > 3.0:
                network_manager.establish_connection()
            else:
                # Stop robot while waiting for reconnection attempt
                hardware['left_motor'].setVelocity(0.0)
                hardware['right_motor'].setVelocity(0.0)
            # Update visualization even if disconnected, but show current error/status
            if current_time - last_viz_update_time > VIZ_UPDATE_INTERVAL_SEC:
                visualization.update_display(robot_world_pose, current_grid_position, line_detected, planned_path,
                                             obstacle_detector.detected_obstacles, # Use the full set for map drawing
                                             processed_camera_image,
                                             current_position_error, current_orientation_error)
                last_viz_update_time = current_time
            continue # Skip the rest of the loop if not connected
        
        # Send data to ESP32
        if current_time - last_data_transmission > 0.1: # Send status every 0.1 seconds
            navigation_data = {
                'type': 'webots_status',
                'robot_grid_pos': list(current_grid_position),
                'goal_grid_pos': [GOAL_ROW, GOAL_COL],
                'world_pose': {
                    'x': round(robot_world_pose['x'], 3),
                    'z': round(robot_world_pose['z'], 3),
                    'theta_rad': round(robot_world_pose['theta'], 3)
                },
                'sensors_binary': line_detected,
                'detected_obstacles': obstacle_detector.get_recent_obstacles() # Send only newly detected obstacles
            }
            
            if not network_manager.send_data(navigation_data):
                # Connection lost during send, handled by NetworkManager and loop continues to reconnect logic
                hardware['left_motor'].setVelocity(0.0)
                hardware['right_motor'].setVelocity(0.0)
                continue
            last_data_transmission = current_time
        
        # Receive commands from ESP32
        received_messages = network_manager.receive_data()
        if not network_manager.is_connected: # Check again in case receive_data lost connection
            hardware['left_motor'].setVelocity(0.0)
            hardware['right_motor'].setVelocity(0.0)
            continue

        for message in received_messages:
            try:
                esp_data = json.loads(message)
                if esp_data.get('type') == 'esp32_command':
                    new_command = esp_data.get('action', 'stop')
                    # If ESP32 changes from a turn command, reset Webots' turn controller
                    if (new_command != esp32_command and 
                        esp32_command in ['turn_left', 'turn_right'] and 
                        new_command not in ['turn_left', 'turn_right']):
                        turn_controller.reset()
                    esp32_command = new_command
                    # Use the path from ESP32, convert tuples back to lists for consistency if needed by visualization
                    # The ESP32 is sending `path: nav_controller.planned_path` which is a list of tuples already.
                    planned_path = esp_data.get('path', planned_path) 
            except json.JSONDecodeError as e:
                # print(f"Webots JSON Decode Error from ESP32: {e}. Message: {message}")
                pass # Ignore malformed JSON messages, or print for debugging during development
            except Exception as e:
                print(f"Webots Error processing ESP32 command: {e}. Message: {message}")
        
        # Determine effective command based on sensor state and ESP32 command
        sensors_detect_line = any(line_detected)
        
        effective_command = esp32_command # Default to ESP32's command
        if turn_controller.is_turning(): # If Webots is in an active turn phase
            effective_command = turn_controller.active_command # Keep executing the turn
            if esp32_command == 'stop': # Allow ESP32 to force a stop
                turn_controller.reset()
                effective_command = 'stop'
        elif sensors_detect_line and esp32_command not in ['turn_left', 'turn_right', 'stop']:
            # If on a line and not actively turning by ESP32, prioritize line following
            effective_command = 'forward' 
        elif not sensors_detect_line and esp32_command == 'forward':
            # If off line and ESP32 says forward, initiate a search turn
            effective_command = 'turn_left' # Default turn direction if line lost

        # Execute movement commands
        left_speed, right_speed = 0.0, 0.0
        
        if effective_command == 'stop':
            turn_controller.reset()
        elif effective_command == 'forward':
            turn_controller.reset()
            left_speed, right_speed = calculate_line_following_speeds(line_detected)
        elif effective_command in ['turn_left', 'turn_right']:
            turn_controller.initiate_turn(effective_command, current_time)
            left_speed, right_speed = turn_controller.execute_turn(effective_command, line_detected, current_time)
        
        # Apply motor velocities
        hardware['left_motor'].setVelocity(left_speed)
        hardware['right_motor'].setVelocity(right_speed)
        
        # Update visualization (rate-limited)
        if current_time - last_viz_update_time > VIZ_UPDATE_INTERVAL_SEC:
            visualization.update_display(robot_world_pose, current_grid_position, line_detected, planned_path,
                                         obstacle_detector.detected_obstacles, # Use the full set for map drawing
                                         processed_camera_image,
                                         current_position_error, current_orientation_error) # Pass errors
            last_viz_update_time = current_time
        
        # Status reporting (rate-limited)
        if iteration_count % 100 == 0:
            connection_status = "Connected" if network_manager.is_connected else "Disconnected"
            sensor_status = "Line Detected" if any(line_detected) else "No Line"
            
            # Format error strings to handle NaN gracefully
            pos_err_str = f"{current_position_error:.3f}" if not math.isnan(current_position_error) else "N/A"
            orient_err_str = f"{math.degrees(current_orientation_error):.1f}" if not math.isnan(current_orientation_error) else "N/A"

            print(f"Status: ESP32 {connection_status} | {sensor_status} | Grid: {current_grid_position} | "
                  f"Pos Error: {pos_err_str} m | Orient Error: {orient_err_str} deg") # Print errors
            
    # Cleanup
    network_manager.close_connection()
    if visualization.figure:
        plt.ioff()
        plt.show(block=True)


if __name__ == "__main__":
    main()
